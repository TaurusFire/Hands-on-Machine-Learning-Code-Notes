{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 Problems\n",
    "This notebook attempts to solve the problems in Chapter 3 of \"Aurélien Géron - Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow_ Concepts, Tools, and Techniques to Build Intelligent Systems-O'Reilly Media (2022)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tarfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "1. Try to build a classifier for the MNIST dataset that achieves over 97% accuracy on the test set. Hint: the KNeighborsClassifier works quite well for this task; you just need to find good hyperparameter values (try a grid search on the weights and n_neighbors hyperparameters).\n",
    "\n",
    "### Create training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cheks/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', as_frame=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist.data, mnist.target\n",
    "some_input = X[0] #this is a 5\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and create classifier\n",
    "train a KNeighbours classifier using a grid search to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn_clf = KNeighborsClassifier() #weights and n_neighbours hyperparameters\n",
    "\n",
    "param_grid = [{'n_neighbors': [3,4,5,6],\n",
    "               'weights': ['distance']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [3, 4, 5, 6],\n",
       "                          &#x27;weights&#x27;: [&#x27;distance&#x27;]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [3, 4, 5, 6],\n",
       "                          &#x27;weights&#x27;: [&#x27;distance&#x27;]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [3, 4, 5, 6],\n",
       "                          'weights': ['distance']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(knn_clf, \n",
    "                           param_grid= param_grid,\n",
    "                           cv = 3,\n",
    "                           scoring= 'accuracy'\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.388008</td>\n",
       "      <td>0.045787</td>\n",
       "      <td>13.503045</td>\n",
       "      <td>1.119890</td>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
       "      <td>0.97040</td>\n",
       "      <td>0.96890</td>\n",
       "      <td>0.96870</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395728</td>\n",
       "      <td>0.067663</td>\n",
       "      <td>12.637795</td>\n",
       "      <td>0.844099</td>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 4, 'weights': 'distance'}</td>\n",
       "      <td>0.97090</td>\n",
       "      <td>0.96980</td>\n",
       "      <td>0.97035</td>\n",
       "      <td>0.970350</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343985</td>\n",
       "      <td>0.015807</td>\n",
       "      <td>11.984878</td>\n",
       "      <td>0.186812</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
       "      <td>0.96880</td>\n",
       "      <td>0.96795</td>\n",
       "      <td>0.96905</td>\n",
       "      <td>0.968600</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.338791</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>12.043371</td>\n",
       "      <td>0.321882</td>\n",
       "      <td>6</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
       "      <td>0.97005</td>\n",
       "      <td>0.96855</td>\n",
       "      <td>0.96985</td>\n",
       "      <td>0.969483</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.388008      0.045787        13.503045        1.119890   \n",
       "1       0.395728      0.067663        12.637795        0.844099   \n",
       "2       0.343985      0.015807        11.984878        0.186812   \n",
       "3       0.338791      0.006227        12.043371        0.321882   \n",
       "\n",
       "  param_n_neighbors param_weights                                     params  \\\n",
       "0                 3      distance  {'n_neighbors': 3, 'weights': 'distance'}   \n",
       "1                 4      distance  {'n_neighbors': 4, 'weights': 'distance'}   \n",
       "2                 5      distance  {'n_neighbors': 5, 'weights': 'distance'}   \n",
       "3                 6      distance  {'n_neighbors': 6, 'weights': 'distance'}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.97040            0.96890            0.96870         0.969333   \n",
       "1            0.97090            0.96980            0.97035         0.970350   \n",
       "2            0.96880            0.96795            0.96905         0.968600   \n",
       "3            0.97005            0.96855            0.96985         0.969483   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.000759                3  \n",
       "1        0.000449                1  \n",
       "2        0.000471                4  \n",
       "3        0.000665                2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, y_test) #use .score to return the score using the given data when the best estimator has already been found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Data Augmentation\n",
    "\n",
    "Write a function that can shift an MNIST image in any direction (left, right, up, or down) by one pixel.⁠ Then, for each image in the training set, create four shifted copies (one per direction) and add them to the training set. Finally, train your best model on this expanded training set and measure its accuracy on the test set. You should observe that your model performs even better now! This technique of artificially growing the training set is called data augmentation or training set expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digit(input_data):\n",
    "    image = input_data.reshape(28,28)\n",
    "    plt.imshow(image, cmap = \"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def shift(image, direction):\n",
    "    shifted_image = image.copy()\n",
    "\n",
    "    if direction == 'down':\n",
    "    #if shifting down, move values 28 spaces along\n",
    "\n",
    "        for i in range(len(image)):\n",
    "            if i<=727:\n",
    "                shifted_image[i+28] = image[i]\n",
    "        \n",
    "        for i in range(28):\n",
    "            shifted_image[i] = 0\n",
    "\n",
    "    if direction == 'up':\n",
    "    #if shifting up, move values 28 spaces behind\n",
    "        \n",
    "        for i in range(len(image)):\n",
    "            if i>=28 and i < 756:\n",
    "                shifted_image[i-28] = image[i]\n",
    "\n",
    "            if i >=756:\n",
    "                shifted_image[i] = 0\n",
    "\n",
    "    if direction == 'left':\n",
    "    #if shifting left, move values 1 space back (but not left edge, i.e. multiples of 28)\n",
    "\n",
    "        for i in range(len(image)):\n",
    "            if i % 28 != 0:\n",
    "                shifted_image[i-1] = image[i]\n",
    "        \n",
    "        for i in range(28):\n",
    "            shifted_image[i*28] = 0\n",
    "        \n",
    "    if direction == 'right':\n",
    "    #if shifting right, move values 1 space forward (but not right edge, i.e. 27 + multiples of 28)\n",
    "\n",
    "        for i in range(len(image)):\n",
    "            if i % 28 != 27:\n",
    "                shifted_image[i] = image[i+1]\n",
    "        \n",
    "        for i in range(27):\n",
    "            shifted_image[(i*28)+27] = 0\n",
    "    \n",
    "    return shifted_image\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(3,3,5)\n",
    "show_digit(X[0])\n",
    "plt.subplot(3,3,8)\n",
    "show_digit(shift(X[0], 'right'))\n",
    "plt.subplot(3,3,2)\n",
    "show_digit(shift(X[0], 'left'))\n",
    "plt.subplot(3,3,4)\n",
    "show_digit(shift(X[0], 'up'))\n",
    "plt.subplot(3,3,6)\n",
    "show_digit(shift(X[0], 'down'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_copies(image):\n",
    "    return shift(image, 'up'), shift(image, 'down'), shift(image, 'left'), shift(image, 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = list(X_train.copy())\n",
    "y_train_new = list(y_train.copy())\n",
    "for i in range(len(X_train)):\n",
    "    for shifted_image in create_shifted_copies(X_train[i]):\n",
    "        X_train_new.append(shifted_image)\n",
    "        y_train_new.append(y_train[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = np.array(X_train_new)\n",
    "y_train_new = np.array(y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle new training set\n",
    "shuffle_ids = np.random.permutation(300000)\n",
    "X_train_new = X_train_new[shuffle_ids]\n",
    "y_train_new = y_train_new[shuffle_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Using the Titanic dataset. The goal is to train a classifier that can predict the Survived column based on the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_path = Path('titanic.tgz')\n",
    "if not titanic_path.is_file():\n",
    "    with tarfile.open('titanic.tgz') as titanic_tarball:\n",
    "        titanic_tarball.extractall()\n",
    "\n",
    "titanic_train = pd.read_csv('titanic/train.csv')\n",
    "titanic_test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen 'Carrie'</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen 'Carrie'  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cheks/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass Sex   Age  SibSp  Parch     Fare    0    1    2    3\n",
       "0         3   0  22.0      1      0   7.2500  0.0  0.0  1.0  0.0\n",
       "1         1   1  38.0      1      0  71.2833  1.0  0.0  0.0  0.0\n",
       "2         3   1  26.0      0      0   7.9250  0.0  0.0  1.0  0.0\n",
       "3         1   1  35.0      1      0  53.1000  0.0  0.0  1.0  0.0\n",
       "4         3   0  35.0      0      0   8.0500  0.0  0.0  1.0  0.0\n",
       "..      ...  ..   ...    ...    ...      ...  ...  ...  ...  ...\n",
       "886       2   0  27.0      0      0  13.0000  0.0  0.0  1.0  0.0\n",
       "887       1   1  19.0      0      0  30.0000  0.0  0.0  1.0  0.0\n",
       "888       3   1   NaN      1      2  23.4500  0.0  0.0  1.0  0.0\n",
       "889       1   0  26.0      0      0  30.0000  1.0  0.0  0.0  0.0\n",
       "890       3   0  32.0      0      0   7.7500  0.0  1.0  0.0  0.0\n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tit_X_train = titanic_train.drop(titanic_train.columns[[0,1,3,8,10]], axis=1)\n",
    "tit_y_train = titanic_train.iloc[:,1]\n",
    "\n",
    "tit_X_train['Sex'] = ['0' if i == 'male' else '1' for i in tit_X_train['Sex'] ]\n",
    "tit_embarked = tit_X_train[['Embarked']] \n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "tit_embarked_one_hot = pd.DataFrame(one_hot_encoder.fit_transform(tit_embarked))\n",
    "tit_X_train = tit_X_train.drop('Embarked', axis=1)\n",
    "tit_X_train.join(tit_embarked_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try building a random forest?\n",
    "titanic_forest = RandomForestClassifier(random_state= 1610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {'titanic_forest__max_features' : randint(low = 2, high = 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Cheks/Desktop/Projects Practice/Coding Practice/Hands-on Machine Learning Code+Notes/Chapter 3- Classification/Chapter 3 Problems.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Cheks/Desktop/Projects%20Practice/Coding%20Practice/Hands-on%20Machine%20Learning%20Code%2BNotes/Chapter%203-%20Classification/Chapter%203%20Problems.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_prob_forest \u001b[39m=\u001b[39m cross_val_predict(titanic_forest, tit_X_train, tit_y_train, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpredict_proba\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1036\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m-> 1036\u001b[0m predictions \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m   1037\u001b[0m     delayed(_fit_and_predict)(\n\u001b[1;32m   1038\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method\n\u001b[1;32m   1039\u001b[0m     )\n\u001b[1;32m   1040\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m splits\n\u001b[1;32m   1041\u001b[0m )\n\u001b[1;32m   1043\u001b[0m inv_test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(\u001b[39mlen\u001b[39m(test_indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m   1044\u001b[0m inv_test_indices[test_indices] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(test_indices))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1118\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m   1117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m   1119\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(estimator, method)\n\u001b[1;32m   1120\u001b[0m predictions \u001b[39m=\u001b[39m func(X_test)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    349\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    350\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python/lib/python3.9/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "y_prob_forest = cross_val_predict(titanic_forest, tit_X_train, tit_y_train, cv=3, method='predict_proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
